# -*- coding: utf-8 -*-
import datetime
import os
import re
import requests
import asyncio
from dotenv import load_dotenv
import json
import logging
logging.basicConfig(filename='error.log', level=logging.DEBUG)

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import CommandStart, Command, StateFilter
from aiogram.types import Message, CallbackQuery, FSInputFile
from aiogram.utils.keyboard import InlineKeyboardBuilder
from aiogram.utils.callback_answer import CallbackAnswer, CallbackAnswerMiddleware
from aiogram.utils.chat_action import ChatActionSender
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State

import openai
import tiktoken
import pandas as pd

from langchain.embeddings.openai import OpenAIEmbeddings
#from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import MarkdownHeaderTextSplitter
#from langchain.vectorstores import FAISS
from langchain_community.vectorstores import FAISS

import matplotlib.pyplot as plt


# –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –±–æ—Ç–∞
"""
class botConfig:
    def __init__(self):
        load_dotenv('./.env')               # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ .env
        self.api_key = os.environ.get('OPENAI_API_KEY')
        self.bot_token = os.environ.get("BOT_TOKEN")
        self.gpt_model = os.environ.get("OPENAI_MODEL")
        self.users = {}
        self.url =  ''
        self.cnk_size = 1500
        self.temperature = 0.2
        self.prompts =''
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.proxy_On = os.getenv("PROXY_On")
        self.proxy_ip = os.getenv("PROXY_IP")
        self.proxy_port = os.getenv("PROXY_PORT")
        self.proxy_user = os.getenv("PROXY_USER")
        self.proxy_pass = os.getenv("PROXY_PASS")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –≤—Å–µ –ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ .env
        if None in [self.proxy_ip, self.proxy_port, self.proxy_user, self.proxy_pass, self.openai_key, self.telegram_token]:
            raise ValueError("–ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Ñ–∞–π–ª–µ .env")

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
        if self.proxy_On == "True" :
            os.environ['HTTP_PROXY'] = f"http://{self.proxy_user}:{self.proxy_pass}@{self.proxy_ip}:{self.proxy_port}"
            os.environ['HTTPS_PROXY'] = f"http://{self.proxy_user}:{self.proxy_pass}@{self.proxy_ip}:{self.proxy_port}"        
"""
#------------------------------------------------------------------------------------------------------------------------------        

# –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –±–æ—Ç–∞
class botConfig:
    def __init__(self):
        load_dotenv('./.env')  # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ .env
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        env_vars = ["OPENAI_API_KEY", "BOT_TOKEN", "GPT_MODEL", "PROXY_On", "PROXY_IP", "PROXY_PORT", "PROXY_USER", "PROXY_PASS"]
        for var in env_vars:   setattr(self, var.lower(), os.getenv(var))

        self.users = {}
        self.url = ''
        self.cnk_size = 1500
        self.temperature = 0.2
        self.prompts = ''

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        if self.proxy_on == "True":
            if not all([getattr(self, var.lower()) for var in env_vars]):
                raise ValueError("–ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Ñ–∞–π–ª–µ .env")
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            proxy = f"http://{self.proxy_user}:{self.proxy_pass}@{self.proxy_ip}:{self.proxy_port}"
            os.environ['HTTP_PROXY'] = os.environ['HTTPS_PROXY'] = proxy

#------------------------------------------------------------------------------------------------------------------------------        

    def get_user(self, user_id):
        if not user_id in self.users:
            self.prompts = {}
            with open('prompts.json', 'r', encoding='utf-8') as file:
              self.prompts = json.load(file)

            self.users[user_id] = {
                'openai_api_key': self.openai_api_key if user_id ==  201173615 else '',
                'gpt_model': self.gpt_model,
                'prompts' : self.prompts,
                'url': self.url,
                'temperature': self.temperature,
                'cnk_size': self.cnk_size,
                'verbose': 0,
                'history': [],
                'summary': ''
            }
            print("New user: ", user_id)

        return self.users[user_id]

    def set_user_param(self, user_id, param, value):
        self.users[user_id][param] = value
#------------------------------------------------------------------------------------------------------------------------------        

# –ö–ª–∞—Å—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI
class OpenAIIntegration:
    def __init__(self, botConfig):
        self.config = botConfig
        self.ai = openai
        self.ai.openai_api_key = self.config['openai_api_key']
        self.gpt_model = self.config['gpt_model']
        self.prompts = self.config['prompts']
        self.chunks = TextProcessor(self.config)
        self.prices = {
            'gpt-3.5-turbo-16k': {
                'prompt': 0.001,
                'completion': 0.002
            },
            'gpt-3.5-turbo': {
                'prompt': 0.0015,
                'completion': 0.002
            },
            'gpt-3.5-turbo-0301': {
                'prompt': 0.0015,
                'completion': 0.002
            },
            'gpt-4': {
                'prompt': 0.03,
                'completion': 0.06
            },
            'gpt-4-1106-preview': {
                'prompt': 0.01,
                'completion': 0.03
            }
        }

    def generate_response(self, prompt):

        

        # Prepeare chunks
        chunks = self.chunks.get_rel_chunks(prompt, 3)

        lvl = 0.5

        knowledge = ""
        for index, (chunk, score) in enumerate(chunks):
            if score <= lvl:
                print(score, len(chunk.page_content))
                knowledge += f"–ß–∞–Ω–∫ –∏–∑ –ë–ó #{index} –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:{round(score, 5)}\n{chunk.page_content}\n\n"

        if knowledge == '':
            knowledge = "Common knowledge"

        print(len(chunks))
        history = ""
        for dialog in self.config['history'][-5:]:
            history += f'\n{dialog}\n'

        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI GPT.
        """

        system_text = f'{self.prompts}'
                
                # –°–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
        chat_messages = [
            {"role": "system", "content": system_text},
            {
                "role": "user",
                "content": f"Please answer the user's question \"{prompt}\" using the information from the knowledge base \"{knowledge}\". Aim for a complete and thorough response, focusing on relevant details only. If the knowledge base lacks specific information for the user's question, craft an answer based on your expertise but clearly indicate the source of your knowledge. Avoid explicit references to documents or the database. Convey to the user that the knowledge base's information is integrated into your understanding. Respond in the user's preferred language; default to Russian if unspecified."
            }
        ]                



        try:
            response = self.ai.ChatCompletion.create(
                model=self.gpt_model,
                messages=chat_messages,
                temperature=float(self.config['temperature'])
            )
            # Generate UUID
            current_datetime = datetime.datetime.now()
            id = int(f"{current_datetime.strftime('%Y%m%d%H%M%S')}{current_datetime.microsecond}")

            answer = response.choices[0].message['content'].strip()
            dialog = {"id": id, "model": self.gpt_model, "tokens_prompt": response.usage["prompt_tokens"],
                      "tokens_total": response.usage["total_tokens"], "price_usd": round(
                    self.get_price(response.usage["prompt_tokens"], response.usage["completion_tokens"]), 5),
                      "question": prompt, "answer": answer, "score": None, "chunks": knowledge}
            self.config['history'].append(dialog)
            # self.config['summary'] = self.summarize_dialog(prompt, answer)
            info = ''
            if self.config['verbose']:
                info = f'''
–ú–æ–¥–µ–ª—å: {self.gpt_model.upper()}                
–¢–æ–∫–µ–Ω—ã (–ü—Ä–æ–º–ø—Ç/–û—Ç–≤–µ—Ç/–í—Å–µ–≥–æ): {response.usage["prompt_tokens"]}/{response.usage["completion_tokens"]}/{response.usage["total_tokens"]}
–¶–µ–Ω–∞: ${round(self.get_price(response.usage["prompt_tokens"], response.usage["completion_tokens"]), 5)} / {round(self.get_price(response.usage["prompt_tokens"], response.usage["completion_tokens"]) * 90, 2)} —Ä—É–±. 
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ë–ó:
{knowledge}
                '''

            return [id, answer, info]
        except openai.error.OpenAIError as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ—à–∏–±–æ–∫ –æ—Ç API
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI: {e}")
            return None

    def get_price(self, prompt, compl):
        modelPrice = self.prices[self.gpt_model]
        price = (prompt * modelPrice['prompt'] + compl * modelPrice['completion']) / 1000
        return price

    def summarize_dialog(self, q, a):

        max_tokens = 1000
        temperature = 0

        system_text = '''
        –¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—Ç–æ—Ä –∫–æ—Ç–æ—Ä—ã–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–µ–¥–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –±–æ–ª–µ–∑–Ω–µ–π –∏ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π, –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –æ —á–µ–º –≤–µ–¥–µ—Ç—Å—è –¥–∏–∞–ª–æ–≥ —Å –∫–ª–∏–µ–Ω—Ç–æ–º.
        –¢—ã –æ–±—è–∑–∞–Ω –∫–∞–∫ –º–∏–Ω–∏–º—É–º –¥–µ—Ä–∂–∞—Ç—å —Å–º—ã—Å–ª –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 —Å–æ–æ–±—â–µ–Ω–∏–π. 
        '''

        # –°–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
        chat_messages = [
            {"role": "system", "content": system_text},
            {"role": "user",
             "content": f"–ü—Ä–µ–¥—ã–¥—É—â–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: {self.config['summary']}\n\–ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –æ—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞: \n{q}\n\n –í–æ—Ç –æ—Ç–≤–µ—Ç –∫–æ—Ç–æ—Ä—ã–π –ø–∞—Ü–∏–µ–Ω—Ç –ø–æ–ª—É—á–∏–ª: \n{a}"}
        ]

        try:
            response = self.ai.ChatCompletion.create(
                model=self.gpt_model,
                messages=chat_messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return response.choices[0].message['content'].strip()
        except openai.error.OpenAIError as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –æ—à–∏–±–æ–∫ –æ—Ç API
            print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
#------------------------------------------------------------------------------------------------------------------------------        

# –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
class TextProcessor:
    def __init__(self, botConfig):
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self.embeddings = OpenAIEmbeddings()
        if os.path.exists("faiss"):
            print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –§–ê–ò–°!")

            self.db = FAISS.load_local("faiss", OpenAIEmbeddings())

        else:
            knowledge_base = botConfig['url']
            if (('google' in knowledge_base) and ('document' in knowledge_base)):
                self.database = self.load_document_text(knowledge_base)
            elif ('google' in knowledge_base): 
                 knowledge_base= self.convert_drive_link_to_direct_download(knowledge_base)
                 self.database = self.download_doc(knowledge_base)
            else:
                self.database = self.download_doc(knowledge_base)


            # –û—á–∏—Å—Ç–∏—Ç—å –æ—Ç –¥–≤–æ–π–Ω—ã—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –≤–æ–∑–º–æ–∂–Ω–æ –Ω–∞–¥–æ!
            self.chunks = self.split_text(self.database, botConfig['cnk_size'])

            # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ FAISS
            print(f"–°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É FAISS!")
            self.db = FAISS.from_documents(self.chunks, self.embeddings)
            self.db.save_local("faiss")

    def convert_drive_link_to_direct_download(self,link):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Å—ã–ª–∫–∞ —Å—Å—ã–ª–∫–æ–π Google Drive
            if "drive.google.com" in link:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ñ–∞–π–ª–∞ –∏–∑ —Å—Å—ã–ª–∫–∏
                file_id = link.split('/d/')[1].split('/view')[0]
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                direct_download_link = f"https://drive.google.com/uc?export=download&id={file_id}"
                return direct_download_link
            else:
                return "–≠—Ç–æ –Ω–µ —Å—Å—ã–ª–∫–∞ Google Drive."
            
    def get_rel_chunks(self, question, chunks_amount=5, vdb="F"):
        if vdb == "F":
            chunks = self.db.similarity_search_with_score(question, k=chunks_amount)
        else:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ Qdrant
            chunks = self.qdrant.similarity_search_with_score(question, k=chunks_amount)

        return chunks

    def get_embedding(self, text):
        embedding = self.embeddings.encode(text)  # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ —Ç–µ–∫—Å—Ç–∞
        return embedding

    def text_to_markdown(text):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç Markdown.
        """

        def replace_header(match, level):
            header = '#' * level
            return f"{header} {match.group(2)}\n{match.group(2)}"

        text = re.sub(r'^(I{1,3}|IV|V)\. (.+)', lambda m: replace_header(m, 1), text, flags=re.M)
        text = re.sub(r'\*([^\*]+)\*', lambda m: replace_header(m, 2), text)

        return text

    def load_document_text(self, url: str) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ Google Docs –ø–æ URL.
        """
        match_ = re.search(r'/document/d/([a-zA-Z0-9-_]+)', url)
        if not match_:
            raise ValueError('Invalid Google Docs URL')

        doc_id = match_.group(1)
        google_docs_url = f'https://docs.google.com/document/d/{doc_id}/export?format=txt'

        return self.download_doc(google_docs_url)

    


    def download_doc(self, url: str) -> str:
        try:
            response = requests.get(url)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            raise ConnectionError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")

    def num_tokens_from_string(self, string: str, encoding_name: str = 'cl100k_base') -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ"""
        encoding = tiktoken.get_encoding(encoding_name)
        num_tokens = len(encoding.encode(string))
        return num_tokens

    def split_text(self, text, max_count):
        headers_to_split_on = [
            ("#", "Header1"),
            ("##", "Header2"),
            ("###", "Header3"),
            ("####", "Header4"),
            ("#####", "Header5"),
            ("######", "Header6"),
            ("#######", "Header7"),
        ]

        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)
        fragments = markdown_splitter.split_text(text)

        Max_Headers = 6

        for i, chunk in enumerate(fragments, start=0):
            # –û–±—ä–µ–¥–∏–Ω–∏—Ç–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if hasattr(chunk, 'metadata') and hasattr(chunk, 'page_content'):
                # if 'metadata' in chank and 'page_content' in chank:
                meta_data = chunk.metadata
                # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ–ª–µ–π –≤ —Å—Ç—Ä–æ–∫—É —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
                values = [meta_data.get(f'Header{i}', '') for i in range(1, Max_Headers + 1)]
                csv_string = ', '.join(values)
                page_content = chunk.page_content
                combined_content = f"{csv_string}\n{page_content}"
                # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—å –ø–æ–ª—è page_content
                chunk.page_content = combined_content

        return fragments

    def create_index_database(self, documents):
        if not hasattr(self, 'embeddings'):
            self.create_embeddings_model()
        self.db = FAISS.from_documents(documents, OpenAIEmbeddings())

#=====================================================================================================================================================
#!!!!!!!!               –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –±–æ—Ç–∞          !!!!!!!!!!!!!!!!    
#=====================================================================================================================================================
class ConsultDocBot:
    def __init__(self, bot_config):
        self.config = bot_config

        self.bot = Bot(token=self.config.bot_token)
        self.dp = Dispatcher()
        self.dp.callback_query.middleware(CallbackAnswerMiddleware())
        self.parse_mode = ""
        self.available_models = ["gpt-3.5-turbo-16k", "gpt-3.5-turbo", "gpt-3.5-turbo-0301", "gpt-4",
                                 "gpt-4-1106-preview"]

        self. waiting_for_db_path = State()  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø—É—Ç–∏ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö  #16/02/24
        self.waiting_for_key = State()
        self.waiting_for_model = State()
        self.waiting_for_temperature = State()
        self.waiting_for_verbose = State()
        
        #self.waiting_for_db_path = State()  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—É—Ç–∏ –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        # start - –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
        # setup - –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        # help - –ü–æ–º–æ—â—å
        # showgraph - –ì—Ä–∞—Ñ–∏–∫ —á–∞–Ω–∫–æ–≤
        # summary - –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ)
        # history - –ò—Å—Ç–æ—Ä–∏—è

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥
        @self.dp.message(CommandStart())
        async def command_start_handler(message: Message) -> None:

            cfg = self.userConfig(message.from_user.id)

            # 'api_key': self.api_key,
            # 'gpt_model': self.gpt_model,
            # 'url': self.url,
            # 'temperature': self.temperature,
            # 'cnk_size': self.cnk_size,
            # 'patient': patient,
            # 'verbose': 0,
            # 'history': [],
            # 'summary': ''


            print(len(self.config.users))
            for user, params in self.config.users.items():
                print(
                    f"User:{user} => {params['openai_api_key']}, {params['gpt_model']}, {params['temperature']}, {params['verbose']}")

            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏

            print(message)
            await message.answer('–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –í–∞—Å! –≠—Ç–æ –±–æ—Ç –Ω–µ–π—Ä–æ-–∫–æ–Ω—Å–ª—å—Ç–∞–Ω—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏',
                                 parse_mode=self.parse_mode)

        @self.dp.message(Command(commands=['setup']))
        async def command_setup_handler(message: Message, state: FSMContext) -> None:

            cfg = self.userConfig(message.from_user.id)

            file_idx = "./faiss/index.faiss"
            modification_date = ""
            if os.path.exists(file_idx):
                timestamp = os.path.getmtime(file_idx)
                modification_date = datetime.datetime.fromtimestamp(timestamp)

            try:
                t = modification_date.strftime('%H:%M:%S %d.%m.%Y')
            except:
                t = "----"

            msg = f"""
‚öôÔ∏è–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞:
    üïπ–ö–ª—é—á: {'*' * 7 + cfg['openai_api_key'][-5:]}
    üïπ–ú–æ–¥–µ–ª—å: {cfg['gpt_model']}
    üïπ–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {cfg['temperature']}
    üïπ–¢–µ—Ö. –∏–Ω—Ñ–æ (verbose): {"‚úÖ" if cfg['verbose'] > 0 else "‚ùå"}
    üïπ–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (UTC): {t}   
            """

            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏
            builder = InlineKeyboardBuilder()
            builder.add(
                types.InlineKeyboardButton(
                    text="–ö–ª—é—á OpenAI",
                    callback_data="set_new_openai_key"
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="–ú–æ–¥–µ–ª—å",
                    callback_data="change_model"
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                    callback_data="change_temperature"
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="–¢–µ—Ö. –∏–Ω—Ñ–æ",
                    callback_data="change_verbose"
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ë–ó",
                    #callback_data="update_vector_db" request_db_path
                    callback_data="request_db_path"
                    
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="–°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é",
                    callback_data="download_history"
                )
            )
            builder.adjust(2)

            print(message)
            await message.answer(msg, reply_markup=builder.as_markup(), parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "–≤—ã–±–∏—Ä–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ"
#----------------------------------------------------------------------------------------------------------
# –ë–ª–æ–∫ –∑–∞–º–µ–Ω—ã –∫–ª—é—á–∞            
        @self.dp.callback_query(F.data == "set_new_openai_key")
        async def ask_openai_key(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):
            await callback.message.delete()
            await callback.message.answer(f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à OpenAI –∫–ª—é—á", parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "waiting_for_key"
            await state.set_state("waiting_for_key")

        @self.dp.message(StateFilter("waiting_for_key"))
        async def save_openai_key(message: Message, state: FSMContext):

            self.config.set_user_param(message.from_user.id, 'openai_api_key', message.text.strip())
            self.openai_integration = ''

            # await message.delete(message.message_id-1)
            await message.delete()

            await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await message.answer("–ö–ª—é—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
#----------------------------------------------------------------------------------------------------------
        @self.dp.callback_query(F.data == "change_model")
        async def ask_model(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):

            builder = InlineKeyboardBuilder()
            for index, model in enumerate(self.available_models):
                builder.add(
                    types.InlineKeyboardButton(
                        text=model.upper(),
                        callback_data=model
                    )
                )
            builder.adjust(3)

            await callback.message.delete()

            await callback.message.answer(f"–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", reply_markup=builder.as_markup(),
                                          parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "waiting_for_key"
            await state.set_state("waiting_for_model")

        @self.dp.message(StateFilter("waiting_for_model"))
        @self.dp.callback_query(lambda c: c.data in self.available_models)
        async def save_model(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):

            print(callback.data)
            self.config.set_user_param(callback.from_user.id, 'gpt_model', callback.data)
            self.openai_integration = ''

            print(callback.message.message_id)
            await callback.message.delete()

            await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await callback.message.answer("–ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞.")
#----------------------------------------------------------------------------------------------------------
        @self.dp.callback_query(F.data == "change_temperature")
        async def ask_temperature(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):
            await callback.message.delete()
            await callback.message.answer(f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ –±–æ–ª—å—à–µ 0.01 –∏ –¥–æ 1.00",
                                          parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "waiting_for_key"
            await state.set_state("waiting_for_temperature")

        @self.dp.message(StateFilter("waiting_for_temperature"))
        async def save_temperature(message: Message, state: FSMContext):

            self.config.set_user_param(message.from_user.id, 'temperature', message.text.strip())
            self.openai_integration = ''

            # await message.delete(message.message_id-1)
            await message.delete()

            await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await message.answer("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–µ–Ω–∞.")
#----------------------------------------------------------------------------------------------------------
        @self.dp.callback_query(F.data == "change_verbose")
        async def ask_verbose(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):

            builder = InlineKeyboardBuilder()
            builder.add(
                types.InlineKeyboardButton(
                    text="‚úÖ –í–∫–ª",
                    callback_data="set_verbose_1"
                )
            )
            builder.add(
                types.InlineKeyboardButton(
                    text="‚ùå –í—ã–∫–ª",
                    callback_data="set_verbose_0"
                )
            )
            builder.adjust(2)

            await callback.message.delete()

            await callback.message.answer(f"–¢–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é?", reply_markup=builder.as_markup(),
                                          parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "waiting_for_verbose"
            await state.set_state("waiting_for_verbose")

        @self.dp.message(StateFilter("waiting_for_verbose"))
        @self.dp.callback_query(lambda c: 'set_verbose_' in c.data)
        async def save_model(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):

            print(callback.data)
            self.config.set_user_param(callback.from_user.id, 'verbose', int(callback.data[-1]))
            self.openai_integration = ''

            print(callback.message.message_id)
            await callback.message.delete()

            await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await callback.message.answer("–ü–∞—Ä–∞–º–µ—Ç—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–º–µ–Ω–µ–Ω.")
#----------------------------------------------------------------------------------------------------------
# –ë–ª–æ–∫ –∑–∞–ø—Ä–æ—Å–∞ –ø—É—Ç–∏ –∫ –ë–ó
        @self.dp.callback_query(F.data == "request_db_path")
        async def ask_db_path(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):
            await callback.message.delete()
            await callback.message.answer(f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π:", parse_mode=self.parse_mode)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–æ—Å—Ç–æ—è–Ω–∏–µ "waiting_for_path"
            await state.set_state("waiting_for_path")

        @self.dp.message(StateFilter("waiting_for_path"))
        async def update_db_path(message: Message, state: FSMContext):
            cfg = self.userConfig(message.from_user.id)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–ª—é—á–∞ API –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if not cfg.get('openai_api_key'):
                await message.answer("–û—à–∏–±–∫–∞: –∫–ª—é—á API –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–ª—é—á API —Å –ø–æ–º–æ—â—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã.")
                await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Å—Ç–∞–≤—à–µ–π—Å—è —á–∞—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏
                return  # –í—ã—Ö–æ–¥ –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏

            self.config.set_user_param(message.from_user.id, 'url', message.text.strip())
            #self.db_path = ''
            self.db_path = message.text.strip()
            # await message.delete(message.message_id-1)
            await message.delete()

            await state.clear()  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await message.answer(f"–ü—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω =>")

            cfg = self.userConfig(message.from_user.id)
            db_path = cfg['url']
            try:
                folder = db_path  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Ç–∏

                if os.path.exists(folder):
                    for filename in os.listdir(folder):
                        file_path = os.path.join(folder, filename)
                        os.remove(file_path)
                    os.rmdir(folder)

                TextProcessor(cfg)
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!"
            except Exception as e:
                print(e)  # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—à–∏–±–∫–µ –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"

            await message.answer(msg)
            print(msg)

            # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è
            # –î–ª—è aiogram 3.x –∏ –≤—ã—à–µ
            await state.set_state(None)
            #await state.finish()

#----------------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------------
        """  
        @self.dp.callback_query(F.data == "request_db_path")
        async def request_db_path(callback: CallbackQuery):
            # –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å –ø—Ä–æ—Å—å–±–æ–π —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            await callback.message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π:")

            # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, –æ–∂–∏–¥–∞—é—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            await self.waiting_for_db_path.set()

        @self.dp.message(state=self.waiting_for_db_path)
        async def update_vector_db(message: Message, state: FSMContext):
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            db_path = message.text

            cfg = self.userConfig(message.from_user.id)

            try:
                folder = db_path  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Ç–∏

                if os.path.exists(folder):
                    for filename in os.listdir(folder):
                        file_path = os.path.join(folder, filename)
                        os.remove(file_path)
                    os.rmdir(folder)

                TextProcessor(cfg)
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!"
            except Exception as e:
                print(e)  # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—à–∏–±–∫–µ –≤ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"

            await message.answer(msg)
            print(msg)

            # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è
            await state.finish()
        """




        """
        @self.dp.callback_query(F.data == "update_vector_db")
        async def update_vector_db(callback: CallbackQuery, callback_answer: CallbackAnswer):

            cfg = self.userConfig(callback.from_user.id)

            try:
                folder = "faiss"

                if os.path.exists(folder):
                    for filename in os.listdir(folder):
                        file_path = os.path.join(folder, filename)
                        os.remove(file_path)
                    os.rmdir(folder)

                TextProcessor(cfg)
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!"
                callback_answer.text = msg
            except:
                msg = "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"
                callback_answer.text = msg
                callback_answer.cache_time = 10
            await callback.message.answer(msg)
            print(msg)            
            """
 #----------------------------------------------------------------------------------------------------------           
        @self.dp.callback_query(F.data == "download_history")
        async def download_history_xls(callback: CallbackQuery, callback_answer: CallbackAnswer):

            cfg = self.userConfig(callback.from_user.id)

            if not len(cfg["history"]):
                callback_answer.text = "–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞—è!"
                callback_answer.cache_time = 10
                return

            # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            df = pd.DataFrame(cfg["history"])

            # –°–æ–∑–¥–∞–µ–º Excel-—Ñ–∞–π–ª (xlsx)
            file_name = "output.xlsx"
            df.to_excel(file_name, index=False)

            print(f"–°–æ–∑–¥–∞–Ω Excel-—Ñ–∞–π–ª: {file_name}")

            try:

                input_file = FSInputFile(path=file_name, filename="history.xlsx")
                await self.bot.send_document(chat_id=callback.message.chat.id, document=input_file,
                                             caption="Excel-—Ñ–∞–π–ª —Å –∏—Å—Ç–æ—Ä–∏–µ–π")

                # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
                os.remove("output.xlsx")

                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è callback_query
                msg = "Excel-—Ñ–∞–π–ª —Å –∏—Å—Ç–æ—Ä–∏–µ–π –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω."
                callback_answer.text = msg

            except:
                msg = "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞: –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"
                callback_answer.text = msg
                callback_answer.cache_time = 10
                await callback.message.answer(msg)

            print(msg)
#----------------------------------------------------------------------------------------------------------
        ### –ö–æ–º–∞–Ω–¥—ã!!!

        @self.dp.message(Command(commands=['help']))
        async def command_help_handler(message: types.Message):
            cfg = self.userConfig(message.from_user.id)
            msg = f'''
/start - –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
/setup - –ù–∞—Å—Ç—Ä–æ–π–∫–∏
/help - –ü–æ–º–æ—â—å
/showgraph - –ì—Ä–∞—Ñ–∏–∫ —á–∞–Ω–∫–æ–≤
/summary - –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (–Ω–µ –∞–∫—Ç–∏–≤–Ω–æ)
/history - –ò—Å—Ç–æ—Ä–∏—è
            '''
            await message.answer(f"{msg}", parse_mode=self.parse_mode)

        @self.dp.message(Command(commands=['summary']))
        async def command_summary_handler(message: types.Message):
            cfg = self.userConfig(message.from_user.id)
            await message.answer(f"Summary:\n{cfg['summary']}", parse_mode=self.parse_mode)

        @self.dp.message(Command(commands=['history']))
        async def command_history_handler(message: types.Message):
            cfg = self.userConfig(message.from_user.id)
            history = ""
            for dialog in cfg['history'][-5:]:
                history += f'\n–í–æ–ø—Ä–æ—Å: {dialog["question"]}\n–û—Ç–≤–µ—Ç: {dialog["answer"]}\n–û—Ü–µ–Ω–∫–∞: {dialog["score"]}\n'

            parts = [history[i:i + 1000] for i in range(0, len(history), 1000)]
            await message.answer(f'History:', parse_mode=self.parse_mode)
            for part in parts:
                await message.answer(f'{part}', parse_mode=self.parse_mode)

        @self.dp.message(Command(commands=['showgraph']))
        async def command_showgraph_handler(message: types.Message):


            db = FAISS.load_local("faiss", OpenAIEmbeddings())
            showchunks = 0
            gstart = 0
            gend = 10000
            parsed_msg = message.text.split(" ")
            for idx in parsed_msg:
                p = idx.split("=")
                if p[0] == "gstart":
                    gstart = int(p[1])
                if p[0] == "gend":
                    gend = int(p[1])
                if p[0] == "showchunks":
                    showchunks = int(p[1])


            sizes = []
            samples = []
            t = TextProcessor(self.config)
            for doc in db.docstore._dict:
                size = t.num_tokens_from_string(db.docstore._dict[doc].page_content)
                # size = len(db.docstore._dict[doc].page_content)
                if size > gstart and size < gend:
                    sizes.append(size)
                    if showchunks and size < showchunks:
                        samples.append(db.docstore._dict[doc].page_content)


            # print(sizes)
            plt.hist(sizes, bins=100)
            plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            plt.xlabel("–†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ç–æ–∫–µ–Ω—ã!)")
            plt.ylabel("–ß–∏—Å–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

            plt.tight_layout()
            plt.savefig("graph.png")
            # plt.show()

            photo = FSInputFile(r'graph.png')
            await message.answer_photo(photo, caption=f'Graph (–≤—Å–µ–≥–æ: {len(sizes)})')
            if showchunks:
                lst = '\n'.join(samples)
                await message.answer(f'''
–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫—É—Å–∫–æ–≤ —Å —Ä–∞–∑–º–µ—Ä–æ–º –¥–æ {showchunks} —Å–∏–º–≤–æ–ª–æ–≤: {len(samples)}
{lst[:4000]}             
                ''')

       
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        @self.dp.message()
        async def message_handler(message: types.Message):

            async with ChatActionSender.typing(chat_id=message.chat.id, bot=self.bot):

                cfg = self.userConfig(message.from_user.id)
                if not (self.checkConfig(cfg) or self.openai_integration):
                    await message.answer(
                        f'–û—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ-–ø–æ–º–æ—â–Ω–∏–∫–∞:\n–£ –≤–∞—Å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –∫–ª—é—á/–º–æ–¥–µ–ª—å!\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–ª—é—á–∞ –Ω–∞–∂–º–∏—Ç–µ /openai_key\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏',
                        parse_mode=self.parse_mode)
                    return

                user_text = message.text
                builder = InlineKeyboardBuilder()

                try:
                    openai_integration = OpenAIIntegration(cfg)
                    msg_id, response, info = openai_integration.generate_response(user_text)
                    builder.add(
                        types.InlineKeyboardButton(
                            text="-2",
                            callback_data=f"set_answer_score_0_{msg_id}"
                        )
                    )
                    builder.add(
                        types.InlineKeyboardButton(
                            text="-1",
                            callback_data=f"set_answer_score_1_{msg_id}"
                        )
                    )
                    builder.add(
                        types.InlineKeyboardButton(
                            text="0",
                            callback_data=f"set_answer_score_2_{msg_id}"
                        )
                    )
                    builder.add(
                        types.InlineKeyboardButton(
                            text="+1",
                            callback_data=f"set_answer_score_3_{msg_id}"
                        )
                    )
                    builder.add(
                        types.InlineKeyboardButton(
                            text="+2",
                            callback_data=f"set_answer_score_4_{msg_id}"
                        )
                    )
                    
                    
                except Exception as e:
                    print("ERROR! {e}")
                    logging.exception("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI")
                    response = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞!\n{e}"
                    info = ""

                await message.answer(f'–û—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ-–ø–æ–º–æ—â–Ω–∏–∫–∞:\n{response}', reply_markup=builder.as_markup(),
                                     parse_mode=self.parse_mode)
                if len(info) > 0:
                    await message.answer(f'–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:', parse_mode=self.parse_mode)
                    parts = [info[i:i + 1000] for i in range(0, len(info), 1000)]
                    for part in parts:
                        await message.answer(f'{part}', parse_mode=self.parse_mode)

            @self.dp.callback_query(lambda c: "set_answer_score_" in c.data)
            async def save_model(callback: CallbackQuery, callback_answer: CallbackAnswer, state: FSMContext):

                cfg = self.userConfig(callback.from_user.id)
                data = callback.data.split("_")
                id = int(data[-1])
                score = int(data[-2]) - 2

                for dialog in cfg["history"]:
                    if dialog["id"] == id:
                        dialog.update({"score": score})
                self.config.set_user_param(callback.from_user.id, 'history', cfg["history"])

                callback_answer.text = f"–î–∞–Ω–Ω–æ–º—É –æ—Ç–≤–µ—Ç—É –≤—ã —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ –æ—Ü–µ–Ω–∫—É: {'+' if score > 0 else ''}{score}"

            # Others
            @self.dp.callback_query()
            async def cb_handler(callback: CallbackQuery, callback_answer: CallbackAnswer):

                if True:
                    callback_answer.text = "–û—Ç–ª–∏—á–Ω–æ!"
                else:
                    callback_answer.text = "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ"
                    callback_answer.cache_time = 10

    class ChangeKey(StatesGroup):
        waiting_for_key = State()  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ –∫–ª—é—á–∞

    def userConfig(self, user_id):
        cfg = self.config.get_user(user_id)
        return cfg

    

    def checkConfig(self, cfg):
        # 'api_key': self.api_key,
        # 'gpt_model': self.gpt_model,
        # 'url': self.url,
        # 'temperature': self.temperature,
        # 'cnk_size': self.cnk_size,
        # 'verbose': 0,
        # 'history': [],
        # 'summary': ''
        return cfg['openai_api_key'] or cfg['gpt_model']

    async def run(self):
        print("Starting  Bot...")
        await self.dp.start_polling(self.bot, skip_updates=True)
#=====================================================================================================================================================
# –ö–æ–Ω–µ—Ü  class ConsultDocBot
#=====================================================================================================================================================


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞
if __name__ == "__main__":
    logging.getLogger("langchain.text_splitter").setLevel(logging.ERROR)
    logging.getLogger("chromadb").setLevel(logging.ERROR)

    config = botConfig()
    userid= 5773050493
    user=config.get_user( userid)
    print(config.users)

    bot = ConsultDocBot(config)
    asyncio.run(bot.run())
